{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "pckC6j__PNBy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, hamming_loss, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
        "from torch.optim import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "from datasets import Dataset as HFDataset\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SYohR2wadFX2"
      },
      "outputs": [],
      "source": [
        "CSV_FILE = Path(\"Annotate _ Datasets - Annotation v3 FINAL NA BEH.csv\")\n",
        "TEXT_COLUMN = \"Text\"\n",
        "LABEL_COLUMNS = [\n",
        "    \"Age\",\n",
        "    \"Gender\",\n",
        "    \"Physical\",\n",
        "    \"Race\",\n",
        "    \"Religion\",\n",
        "    \"Politics\",\n",
        "    \"Others\",\n",
        "]\n",
        "MAX_FEATS = 5_000\n",
        "NGRAM_RANGE = (1, 2)\n",
        "UNCERTAINTY_THRESHOLD = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "vNxBW8ZjXqa2",
        "outputId": "27280bd6-c0fb-4d58-cded-d675f30e8367"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Age",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Gender",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Physical",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Race",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Religion",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Politics",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Others",
                  "rawType": "int64",
                  "type": "integer"
                }
              ],
              "ref": "c67dcdf5-90b3-42fc-932c-7bc01e321657",
              "rows": [
                [
                  "0",
                  "Tangina Chinese. Pinapasakop naman tayo ng isang tanga-tangang presidente sa mga chingchong eh",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "1",
                  "ay bakit?porke ba nasa America ka ay di ka na Pinoy?ulol! Magpa-blood transfusion ka man na galing sa Amerikano, Pinoy ka pa rin!! stupido!",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "2",
                  "Ano ba kasing pinaglalaban ng mga Iglesia sa EDSA? Ang gulo na nga dun dinagdagan pa. Parang mga ulol lang.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "3",
                  "Anong nililipad mo dyan PUTANGINA KANG SIRAULO KANG MONGOLOID PILOT KA DYAN SA AIRPORT?!! ILANG BESES KO BANG SASABIHIN NA HINDI AKO INTERESTED NA MAGTRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO KAYA GAWIN MONG REACHABLE ANG LAHAT NG WEBSITES FOR ME NG 24/7 TANGINA KA!!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "4",
                  "The neighbor's smell got in the condo pota amoy bumbay",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "5",
                  "TANGINA PORKET 13 LANG AKO GANYAN NA KAYO SAKEN HAYS MAGBBIRHTDAY DIN KASI AKO WEYT NYO LANG PAKYU GURANG NA KASI KAYO EH",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "6",
                  "Bobo kaba, dito ako nakatira mga kaklase finafillow ako, paano nila maiintindihan pinagsasabi ko pag tinagalog bobo talaga mga pinoy napaka tanga",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "7",
                  "And for the nth time, yawa ang mga lalaki period no erase ulol pakyu.",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "8",
                  "CATHOLICS FUCK YALL FOR DRAGGING THE PURA LUKA ISSUE GANYAN BA YUNG MGA SINASAMBA NYONG DYOS-DYOSAN? YALL R SO HAPPY FOR OTHER'S SUFFERING SO FUCK YALL",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "9",
                  "tangIna faggot kang anak ng pating kang abnoy ka na pisteng ulol ah fucking bitch giatay kang burikat ka na mukang ebak na puno ng kinginamong hayop ka ampanget ng nanay mo ampanget ng tatay mo syempre dika exempted panget ka din tangina mo",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "10",
                  "Mga lalaki talaga mga hayuk sa babae. Tangina. Kakapanood niyo kasi ng pornography videos na pinagsasabay ang mga babae. Mga putangina niyong mga manloloko kayo. Kating kati?",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "11",
                  "Putangina pwede bang itigil na ng matatanda mag sabi ng kababae mong tao ganyan ka like shut the fuck up i didn't ask for your opinion nobody needs your stupid opinion pag babae ka you're supposed to be the taga linis kase you're babae pag lalake ka it's okay -",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "12",
                  "mamatay na sana yung sumaksak sa aso ko, pupulutanin nyo kasi malaki katawan? di payatot noh, alagang alaga eh. mamatay na kayo pls!!!!! putang ina nyo di nyo deserve mabuhay, kayo yung hayop dito.",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "13",
                  "when will ppl understand that, just increasing the volume doesnt equate to sounding good, fuck man nakakapikon tunog dito sa church ansakit sa tenga amputa",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "14",
                  "fuck you and your twisted beliefs. mas genuine pa yung sympathy ng chaplain sa evangelical church ng tabak putangina niyo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "15",
                  "anong gusto mo? sagutin kita? e may jowa ako lol. tanginamo, ante. baliw ka ba???? educ pa naman course mo, tapos ganyan ka. yawa ang bobo mo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "16",
                  "isasama ko kayo sa mga badjao, mga ulol pinagiisipan niyo ako ng masama wag po ako awa na hahahahaha gago",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "17",
                  "bobo ka na pari niluluto yan sa lunch counter ng mga public school kupal ipinamimigay yan tuwing recess ng hapon leader ako noon sa room kaya ako ang taga kuha submit sa lunch counter yung present during that time at tatawagin kapag ready na saan ka ba nagaral noon sa gay bar",
                  "0",
                  "1",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "18",
                  "kadiri sa feeling educated sa fb tapos kunwari palaging tama,, bugok, panget ka na nga, kinulang ka pa sa height, asim mo pa!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "19",
                  "TANGINA NG ADMIN NA TO PUTA RECORDED NA NGA YUNG SOEECH NAPAKATAGAL PA IEDIT MGA PUTANGINANG WALANGHIYA, I-LIVESTREAM NIYO NA LANG NG BUO KAHIT ILANG ORAS YAN GANUN DIN NAMAN WALANG KWENTA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "20",
                  "these filipinos knew damn well how to milk us like yall monkeys should stop migrating here smh",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "21",
                  "Bakit ba ang bobobobo ng mga baby boomers na naka-upo??? Keep up naman mga tanda. Tangina naman nauuumay na kong panuorin kayong mamahala. Nakakawala ng respeto. Pakshit kayo.",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "22",
                  "BOBO SURE AKO NA BY NOW IKINAHIHIYA KA NG MGA TITSER AT KAMG ANAK MO SA KABOBOHAN MO MAG KOMENTO. ANG TANGA TANGA KASI",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "23",
                  "hindi naman ako lalaki para gawin yun tangina gusto ko rin maranasan yon ng kinukusa",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "24",
                  "taena haha kung ano ano pang sinasabi tapos ligwak naman pala sa dl/pl this sem. Bobo HAHA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "25",
                  "TANGINA NI GADGET ADDICT, WALA NANG NAIDULOT KUNG HINDI PURO INTRIGA AT SCANDAL",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "26",
                  "ulol bakla mamatay kana sama mo amo mo",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "27",
                  "Pag supporter talaga ni Deputa tanga, inutil, imbecile, walang dulot ang sinasabi, ignorante, lahat na masasamang words pwede na sabihin. Binadmouth ko talaga haha wala 'kong pake kung matanda ka sa'kin",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "28",
                  "Eng prof men matanda na, sana gahasain siya ng bakla",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "29",
                  "ALA AKONG PAKE SA PERA MO GIRL MAY SARILI AKONG BUHAY ATLIS WALA AKONG SUGAR DADDY BOBO HAYOP NATO TANGINA NAKAILANG ARABO KANA DYAN SA IBANG BANSA TARATANDO KA HAHAHA INIWAN YUNG ASAWA PARA SA ARABO PABUNTIS KA DYAN BE PARA YUMAMAN KA",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "30",
                  "kanina may nakasalubong ako sa elevator mabaho ughhhhhhhhh. amoy putok ng bumbay + dying animals. natrauma na ako sa elevator",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "31",
                  "Gago ang pangit nyo talaga kayong matatanda na walang pagkatandaan. Boomer energy ampota",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "32",
                  "hindot na binabae pa.... ngiwi dito ngiwi dun... hahaha",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "33",
                  "Nang gigil nanaman si ako sa mga teenager na to kung mag ano sus. Mga pakyu!",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "34",
                  "Hay ang ganda namang bungad sa umaga. Parang makakasapak ako ng intsik mamaya",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "35",
                  "etong mga madre na mga puta na sumusuporta kay lenitard putangina nyo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0"
                ],
                [
                  "36",
                  "all priests are fucking predators tangina nyong mga puta kayo fucking die in hell",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "37",
                  "Tapos dinpa inallow ung testing center sa Marikina. Pakyu Duque! Magresign ka na po! Isa kang corrupt BOOMER!",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "38",
                  "Nakalimutan na naman uminom ng gamot si Tanda! Hoy GAGO mag kulambo ka na lang. You are not relevant anymore.",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "39",
                  "Ulol. Basta Iglesia talaga bobo.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "40",
                  "Ganon ba dapat mag-act ang isang madre? :/ #MMK\" onga. Sarap patayin eh. HAHAHA. XD",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "41",
                  "uy gago sakit naman lalo na yung ending niyan bwiset yung bata diyan eh",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "42",
                  "Maka millenials naman tong nanay ko eh sarap sabunutan eh.",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "43",
                  "TAPOS TANGINA KANG MONGOLOID PILOT KA, GAANO PA KABAGAL ANG PAGCHI-CHECK MO NG BOX NG reCAPTCHA KUNG HINDI NAMAN AKO PUPUNTA SA PASIG, MALABON AND MANDALUYONG BRANCHES? HINDI RIN AKO MAGTATRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO MONGOLOID PILOT. I'LL TEACH TANGINA.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "44",
                  "may galit talaga ako sa mga iglesia eh. tangina kasi nila. AHAHAHAHA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0"
                ],
                [
                  "45",
                  "hahhahaha mga putanginang bobong bulag n mga suporter to! gutom n sinasampal n ng ktutuhanan mga incompetent bnoto nila tanga tangahan parin!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "1",
                  "0"
                ],
                [
                  "46",
                  "Ang bastos talaga ng ibang baby boomers tangina, ang lumanay ng tono ko sakaniya bigla ba naman akong sabihan ng bastos??",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "47",
                  "You're such a pity thou like why allowing yourself to be that low, tanga tangahan si tanda for free",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0"
                ],
                [
                  "48",
                  "DI KO NILALAHAT AH! PERO TRIGGERED NA TRIEGGERED NA TALAGA AKO EH! S/O SA MGA IMMA FANS JAN NA HALOS LAHAT MGA BABY BRA WARRIORS!! TANGINA NYO AH KUNG WALA KAYONG MAGANDANG MASABI MANAHIMIK NALANG KAYO PWEDE? NAKAKAHIYA KAYO EH! MADAMING MEANING ANG BTS FYI WAG KAYONG MEMA!",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ],
                [
                  "49",
                  "Mag oopinion ka na nga lang mali mali pa bobo ka wala ka masabeng matino utak talangka",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1"
                ]
              ],
              "shape": {
                "columns": 8,
                "rows": 4343
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Physical</th>\n",
              "      <th>Race</th>\n",
              "      <th>Religion</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tangina Chinese. Pinapasakop naman tayo ng isa...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ay bakit?porke ba nasa America ka ay di ka na ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ano ba kasing pinaglalaban ng mga Iglesia sa E...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Anong nililipad mo dyan PUTANGINA KANG SIRAULO...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The neighbor's smell got in the condo pota amo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4338</th>\n",
              "      <td>Ang bagal ng serbisyo kasi puro matatanda ang ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4339</th>\n",
              "      <td>Wala nang naitulong 'yang mga gurang na 'yan, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4340</th>\n",
              "      <td>Mga Gen Z, puro lang salita, wala namang gawa.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4341</th>\n",
              "      <td>Sana mawala na sa sistema 'yang mga tanda na '...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4342</th>\n",
              "      <td>Hindi na nakakasabay sa uso ang mga matatanda,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4343 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Age  Gender  \\\n",
              "0     Tangina Chinese. Pinapasakop naman tayo ng isa...    0       0   \n",
              "1     ay bakit?porke ba nasa America ka ay di ka na ...    0       0   \n",
              "2     Ano ba kasing pinaglalaban ng mga Iglesia sa E...    0       0   \n",
              "3     Anong nililipad mo dyan PUTANGINA KANG SIRAULO...    0       0   \n",
              "4     The neighbor's smell got in the condo pota amo...    0       0   \n",
              "...                                                 ...  ...     ...   \n",
              "4338  Ang bagal ng serbisyo kasi puro matatanda ang ...    1       0   \n",
              "4339  Wala nang naitulong 'yang mga gurang na 'yan, ...    1       0   \n",
              "4340     Mga Gen Z, puro lang salita, wala namang gawa.    1       0   \n",
              "4341  Sana mawala na sa sistema 'yang mga tanda na '...    1       0   \n",
              "4342  Hindi na nakakasabay sa uso ang mga matatanda,...    1       0   \n",
              "\n",
              "      Physical  Race  Religion  Politics  Others  \n",
              "0            0     1         0         1       0  \n",
              "1            0     1         0         0       0  \n",
              "2            0     0         1         0       0  \n",
              "3            1     0         0         0       0  \n",
              "4            1     1         0         0       0  \n",
              "...        ...   ...       ...       ...     ...  \n",
              "4338         0     0         0         0       0  \n",
              "4339         0     0         0         0       0  \n",
              "4340         0     0         0         0       0  \n",
              "4341         0     0         0         0       0  \n",
              "4342         0     0         0         0       0  \n",
              "\n",
              "[4343 rows x 8 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(CSV_FILE, encoding='latin1')\n",
        "df = df.drop(columns= ['Unnamed: 8','Unnamed: 9', 'Unnamed: 10'], axis= 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Stopwords\n",
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "tagalog_stopwords = set([\"akin\",\"aking\",\"ako\",\"alin\",\"am\",\"amin\",\"aming\",\"ang\",\"ano\",\"anumang\",\"apat\",\"at\",\"atin\",\"ating\",\"ay\",\"bababa\",\"bago\",\"bakit\",\"bawat\",\"bilang\",\"dahil\",\"dalawa\",\"dapat\",\"din\",\"dito\",\"doon\",\"gagawin\",\"gayunman\",\"ginagawa\",\"ginawa\",\"ginawang\",\"gumawa\",\"gusto\",\"habang\",\"hanggang\",\"hindi\",\"huwag\",\"iba\",\"ibaba\",\"ibabaw\",\"ibig\",\"ikaw\",\"ilagay\",\"ilalim\",\"ilan\",\"inyong\",\"isa\",\"isang\",\"itaas\",\"ito\",\"iyo\",\"iyon\",\"iyong\",\"ka\",\"kahit\",\"kailangan\",\"kailanman\",\"kami\",\"kanila\",\"kanilang\",\"kanino\",\"kanya\",\"kanyang\",\"kapag\",\"kapwa\",\"karamihan\",\"katiyakan\",\"katulad\",\"kaya\",\"kaysa\",\"ko\",\"kong\",\"kulang\",\"kumuha\",\"kung\",\"laban\",\"lahat\",\"lamang\",\"likod\",\"lima\",\"maaari\",\"maaaring\",\"maging\",\"mahusay\",\"makita\",\"marami\",\"marapat\",\"masyado\",\"may\",\"mayroon\",\"mga\",\"minsan\",\"mismo\",\"mula\",\"muli\",\"na\",\"nabanggit\",\"naging\",\"nagkaroon\",\"nais\",\"nakita\",\"namin\",\"napaka\",\"narito\",\"nasaan\",\"ng\",\"ngayon\",\"ni\",\"nila\",\"nilang\",\"nito\",\"niya\",\"niyang\",\"noon\",\"o\",\"pa\",\"paano\",\"pababa\",\"paggawa\",\"pagitan\",\"pagkakaroon\",\"pagkatapos\",\"palabas\",\"pamamagitan\",\"panahon\",\"pangalawa\",\"para\",\"paraan\",\"pareho\",\"pataas\",\"pero\",\"pumunta\",\"pumupunta\",\"sa\",\"saan\",\"sabi\",\"sabihin\",\"sarili\",\"sila\",\"sino\",\"siya\",\"tatlo\",\"tayo\",\"tulad\",\"tungkol\",\"una\",\"walang\"])\n",
        "ALL_STOPWORDS= STOPWORDS.union(tagalog_stopwords)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "ENG_LEMMA = WordNetLemmatizer()\n",
        "\n",
        "def load_lemma_dict(file_path):\n",
        "    lemma_dict = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if ':' in line:\n",
        "                word, lemma = line.strip().split(':')\n",
        "                lemma_dict[word.strip()] = lemma.strip()\n",
        "    return lemma_dict\n",
        "\n",
        "def lemmatize_text(word, lemma_dict):\n",
        "    return lemma_dict.get(word, word)\n",
        "\n",
        "TAGALOG_LEMMA= load_lemma_dict('filipino_lemma.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UyeR1QvBdM_u"
      },
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    if pd.isnull(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Remove stopwords\n",
        "    tokens = text.split()\n",
        "    tokens= [t for t in tokens if t not in ALL_STOPWORDS]\n",
        "    # Lemmatization\n",
        "    lemmatized_tokens = []\n",
        "    for t in tokens:\n",
        "        lemma = TAGALOG_LEMMA.get(t)\n",
        "        if lemma is not None:\n",
        "            lemmatized_tokens.append(lemma)\n",
        "        else:\n",
        "            lemmatized_tokens.append(ENG_LEMMA.lemmatize(t))\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "def tokenize(text: str) -> List[str]:\n",
        "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KZSPFoOjdnF1"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(CSV_FILE)\n",
        "df[\"clean_text\"] = df[TEXT_COLUMN].apply(clean_text)\n",
        "df[\"tokens\"] = df[\"clean_text\"].apply(tokenize)\n",
        "df[\"token_text\"] = df[\"tokens\"].apply(lambda toks: \" \".join(toks))\n",
        "\n",
        "# 60/30/10\n",
        "X_temp, X_val_original, y_temp, y_val = train_test_split(\n",
        "    df[\"token_text\"], df[LABEL_COLUMNS], test_size=0.10, random_state=42\n",
        ")\n",
        "\n",
        "X_train_original, X_test_original, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3333, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Text",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "00f0aa30-cabc-443e-8d27-e9012c05ab63",
              "rows": [
                [
                  "0",
                  "Tangina Chinese. Pinapasakop naman tayo ng isang tanga-tangang presidente sa mga chingchong eh"
                ],
                [
                  "1",
                  "ay bakit?porke ba nasa America ka ay di ka na Pinoy?ulol! Magpa-blood transfusion ka man na galing sa Amerikano, Pinoy ka pa rin!! stupido!"
                ],
                [
                  "2",
                  "Ano ba kasing pinaglalaban ng mga Iglesia sa EDSA? Ang gulo na nga dun dinagdagan pa. Parang mga ulol lang."
                ],
                [
                  "3",
                  "Anong nililipad mo dyan PUTANGINA KANG SIRAULO KANG MONGOLOID PILOT KA DYAN SA AIRPORT?!! ILANG BESES KO BANG SASABIHIN NA HINDI AKO INTERESTED NA MAGTRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO KAYA GAWIN MONG REACHABLE ANG LAHAT NG WEBSITES FOR ME NG 24/7 TANGINA KA!!"
                ],
                [
                  "4",
                  "The neighbor's smell got in the condo pota amoy bumbay"
                ],
                [
                  "5",
                  "TANGINA PORKET 13 LANG AKO GANYAN NA KAYO SAKEN HAYS MAGBBIRHTDAY DIN KASI AKO WEYT NYO LANG PAKYU GURANG NA KASI KAYO EH"
                ],
                [
                  "6",
                  "Bobo kaba, dito ako nakatira mga kaklase finafillow ako, paano nila maiintindihan pinagsasabi ko pag tinagalog bobo talaga mga pinoy napaka tanga"
                ],
                [
                  "7",
                  "And for the nth time, yawa ang mga lalaki period no erase ulol pakyu."
                ],
                [
                  "8",
                  "CATHOLICS FUCK YALL FOR DRAGGING THE PURA LUKA ISSUE GANYAN BA YUNG MGA SINASAMBA NYONG DYOS-DYOSAN? YALL R SO HAPPY FOR OTHER'S SUFFERING SO FUCK YALL"
                ],
                [
                  "9",
                  "tangIna faggot kang anak ng pating kang abnoy ka na pisteng ulol ah fucking bitch giatay kang burikat ka na mukang ebak na puno ng kinginamong hayop ka ampanget ng nanay mo ampanget ng tatay mo syempre dika exempted panget ka din tangina mo"
                ],
                [
                  "10",
                  "Mga lalaki talaga mga hayuk sa babae. Tangina. Kakapanood niyo kasi ng pornography videos na pinagsasabay ang mga babae. Mga putangina niyong mga manloloko kayo. Kating kati?"
                ],
                [
                  "11",
                  "Putangina pwede bang itigil na ng matatanda mag sabi ng kababae mong tao ganyan ka like shut the fuck up i didn't ask for your opinion nobody needs your stupid opinion pag babae ka you're supposed to be the taga linis kase you're babae pag lalake ka it's okay -"
                ],
                [
                  "12",
                  "mamatay na sana yung sumaksak sa aso ko, pupulutanin nyo kasi malaki katawan? di payatot noh, alagang alaga eh. mamatay na kayo pls!!!!! putang ina nyo di nyo deserve mabuhay, kayo yung hayop dito."
                ],
                [
                  "13",
                  "when will ppl understand that, just increasing the volume doesnt equate to sounding good, fuck man nakakapikon tunog dito sa church ansakit sa tenga amputa"
                ],
                [
                  "14",
                  "fuck you and your twisted beliefs. mas genuine pa yung sympathy ng chaplain sa evangelical church ng tabak putangina niyo"
                ],
                [
                  "15",
                  "anong gusto mo? sagutin kita? e may jowa ako lol. tanginamo, ante. baliw ka ba???? educ pa naman course mo, tapos ganyan ka. yawa ang bobo mo"
                ],
                [
                  "16",
                  "isasama ko kayo sa mga badjao, mga ulol pinagiisipan niyo ako ng masama wag po ako awa na hahahahaha gago"
                ],
                [
                  "17",
                  "bobo ka na pari niluluto yan sa lunch counter ng mga public school kupal ipinamimigay yan tuwing recess ng hapon leader ako noon sa room kaya ako ang taga kuha submit sa lunch counter yung present during that time at tatawagin kapag ready na saan ka ba nagaral noon sa gay bar"
                ],
                [
                  "18",
                  "kadiri sa feeling educated sa fb tapos kunwari palaging tama,, bugok, panget ka na nga, kinulang ka pa sa height, asim mo pa!"
                ],
                [
                  "19",
                  "TANGINA NG ADMIN NA TO PUTA RECORDED NA NGA YUNG SOEECH NAPAKATAGAL PA IEDIT MGA PUTANGINANG WALANGHIYA, I-LIVESTREAM NIYO NA LANG NG BUO KAHIT ILANG ORAS YAN GANUN DIN NAMAN WALANG KWENTA"
                ],
                [
                  "20",
                  "these filipinos knew damn well how to milk us like yall monkeys should stop migrating here smh"
                ],
                [
                  "21",
                  "Bakit ba ang bobobobo ng mga baby boomers na naka-upo??? Keep up naman mga tanda. Tangina naman nauuumay na kong panuorin kayong mamahala. Nakakawala ng respeto. Pakshit kayo."
                ],
                [
                  "22",
                  "BOBO SURE AKO NA BY NOW IKINAHIHIYA KA NG MGA TITSER AT KAMG ANAK MO SA KABOBOHAN MO MAG KOMENTO. ANG TANGA TANGA KASI"
                ],
                [
                  "23",
                  "hindi naman ako lalaki para gawin yun tangina gusto ko rin maranasan yon ng kinukusa"
                ],
                [
                  "24",
                  "taena haha kung ano ano pang sinasabi tapos ligwak naman pala sa dl/pl this sem. Bobo HAHA"
                ],
                [
                  "25",
                  "TANGINA NI GADGET ADDICT, WALA NANG NAIDULOT KUNG HINDI PURO INTRIGA AT SCANDAL"
                ],
                [
                  "26",
                  "ulol bakla mamatay kana sama mo amo mo"
                ],
                [
                  "27",
                  "Pag supporter talaga ni Deputa tanga, inutil, imbecile, walang dulot ang sinasabi, ignorante, lahat na masasamang words pwede na sabihin. Binadmouth ko talaga haha wala 'kong pake kung matanda ka sa'kin"
                ],
                [
                  "28",
                  "Eng prof men matanda na, sana gahasain siya ng bakla"
                ],
                [
                  "29",
                  "ALA AKONG PAKE SA PERA MO GIRL MAY SARILI AKONG BUHAY ATLIS WALA AKONG SUGAR DADDY BOBO HAYOP NATO TANGINA NAKAILANG ARABO KANA DYAN SA IBANG BANSA TARATANDO KA HAHAHA INIWAN YUNG ASAWA PARA SA ARABO PABUNTIS KA DYAN BE PARA YUMAMAN KA"
                ],
                [
                  "30",
                  "kanina may nakasalubong ako sa elevator mabaho ughhhhhhhhh. amoy putok ng bumbay + dying animals. natrauma na ako sa elevator"
                ],
                [
                  "31",
                  "Gago ang pangit nyo talaga kayong matatanda na walang pagkatandaan. Boomer energy ampota"
                ],
                [
                  "32",
                  "hindot na binabae pa.... ngiwi dito ngiwi dun... hahaha"
                ],
                [
                  "33",
                  "Nang gigil nanaman si ako sa mga teenager na to kung mag ano sus. Mga pakyu!"
                ],
                [
                  "34",
                  "Hay ang ganda namang bungad sa umaga. Parang makakasapak ako ng intsik mamaya"
                ],
                [
                  "35",
                  "etong mga madre na mga puta na sumusuporta kay lenitard putangina nyo"
                ],
                [
                  "36",
                  "all priests are fucking predators tangina nyong mga puta kayo fucking die in hell"
                ],
                [
                  "37",
                  "Tapos dinpa inallow ung testing center sa Marikina. Pakyu Duque! Magresign ka na po! Isa kang corrupt BOOMER!"
                ],
                [
                  "38",
                  "Nakalimutan na naman uminom ng gamot si Tanda! Hoy GAGO mag kulambo ka na lang. You are not relevant anymore."
                ],
                [
                  "39",
                  "Ulol. Basta Iglesia talaga bobo."
                ],
                [
                  "40",
                  "Ganon ba dapat mag-act ang isang madre? :/ #MMK\" onga. Sarap patayin eh. HAHAHA. XD"
                ],
                [
                  "41",
                  "uy gago sakit naman lalo na yung ending niyan bwiset yung bata diyan eh"
                ],
                [
                  "42",
                  "Maka millenials naman tong nanay ko eh sarap sabunutan eh."
                ],
                [
                  "43",
                  "TAPOS TANGINA KANG MONGOLOID PILOT KA, GAANO PA KABAGAL ANG PAGCHI-CHECK MO NG BOX NG reCAPTCHA KUNG HINDI NAMAN AKO PUPUNTA SA PASIG, MALABON AND MANDALUYONG BRANCHES? HINDI RIN AKO MAGTATRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO MONGOLOID PILOT. I'LL TEACH TANGINA."
                ],
                [
                  "44",
                  "may galit talaga ako sa mga iglesia eh. tangina kasi nila. AHAHAHAHA"
                ],
                [
                  "45",
                  "hahhahaha mga putanginang bobong bulag n mga suporter to! gutom n sinasampal n ng ktutuhanan mga incompetent bnoto nila tanga tangahan parin!"
                ],
                [
                  "46",
                  "Ang bastos talaga ng ibang baby boomers tangina, ang lumanay ng tono ko sakaniya bigla ba naman akong sabihan ng bastos??"
                ],
                [
                  "47",
                  "You're such a pity thou like why allowing yourself to be that low, tanga tangahan si tanda for free"
                ],
                [
                  "48",
                  "DI KO NILALAHAT AH! PERO TRIGGERED NA TRIEGGERED NA TALAGA AKO EH! S/O SA MGA IMMA FANS JAN NA HALOS LAHAT MGA BABY BRA WARRIORS!! TANGINA NYO AH KUNG WALA KAYONG MAGANDANG MASABI MANAHIMIK NALANG KAYO PWEDE? NAKAKAHIYA KAYO EH! MADAMING MEANING ANG BTS FYI WAG KAYONG MEMA!"
                ],
                [
                  "49",
                  "Mag oopinion ka na nga lang mali mali pa bobo ka wala ka masabeng matino utak talangka"
                ]
              ],
              "shape": {
                "columns": 1,
                "rows": 4343
              }
            },
            "text/plain": [
              "0       Tangina Chinese. Pinapasakop naman tayo ng isa...\n",
              "1       ay bakit?porke ba nasa America ka ay di ka na ...\n",
              "2       Ano ba kasing pinaglalaban ng mga Iglesia sa E...\n",
              "3       Anong nililipad mo dyan PUTANGINA KANG SIRAULO...\n",
              "4       The neighbor's smell got in the condo pota amo...\n",
              "                              ...                        \n",
              "4338    Ang bagal ng serbisyo kasi puro matatanda ang ...\n",
              "4339    Wala nang naitulong 'yang mga gurang na 'yan, ...\n",
              "4340       Mga Gen Z, puro lang salita, wala namang gawa.\n",
              "4341    Sana mawala na sa sistema 'yang mga tanda na '...\n",
              "4342    Hindi na nakakasabay sa uso ang mga matatanda,...\n",
              "Name: Text, Length: 4343, dtype: object"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RiIbeNcYYTWV",
        "outputId": "be89ac88-08a7-4fc1-d796-bd7dfd52498f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Age",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Gender",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Physical",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Race",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Religion",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Politics",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Others",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "clean_text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "tokens",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "token_text",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "5b5d1f72-e8d4-4976-96a0-6e1043799221",
              "rows": [
                [
                  "0",
                  "Tangina Chinese. Pinapasakop naman tayo ng isang tanga-tangang presidente sa mga chingchong eh",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "0",
                  "tangina chinese pinapasakop naman tangatangang residente chingchong eh",
                  "['tangina', 'chinese', 'pinapasakop', 'naman', 'tangatangang', 'residente', 'chingchong', 'eh']",
                  "tangina chinese pinapasakop naman tangatangang residente chingchong eh"
                ],
                [
                  "1",
                  "ay bakit?porke ba nasa America ka ay di ka na Pinoy?ulol! Magpa-blood transfusion ka man na galing sa Amerikano, Pinoy ka pa rin!! stupido!",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "bakitporke ba nasa america di pinoyulol magpablood transfusion man gali amerikano pinoy rin stupido",
                  "['bakitporke', 'ba', 'nasa', 'america', 'di', 'pinoyulol', 'magpablood', 'transfusion', 'man', 'gali', 'amerikano', 'pinoy', 'rin', 'stupido']",
                  "bakitporke ba nasa america di pinoyulol magpablood transfusion man gali amerikano pinoy rin stupido"
                ],
                [
                  "2",
                  "Ano ba kasing pinaglalaban ng mga Iglesia sa EDSA? Ang gulo na nga dun dinagdagan pa. Parang mga ulol lang.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "ba kasi laban iglesia edsa gulo nga dun dagan para ulol lang",
                  "['ba', 'kasi', 'laban', 'iglesia', 'edsa', 'gulo', 'nga', 'dun', 'dagan', 'para', 'ulol', 'lang']",
                  "ba kasi laban iglesia edsa gulo nga dun dagan para ulol lang"
                ],
                [
                  "3",
                  "Anong nililipad mo dyan PUTANGINA KANG SIRAULO KANG MONGOLOID PILOT KA DYAN SA AIRPORT?!! ILANG BESES KO BANG SASABIHIN NA HINDI AKO INTERESTED NA MAGTRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO KAYA GAWIN MONG REACHABLE ANG LAHAT NG WEBSITES FOR ME NG 24/7 TANGINA KA!!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "ano nililipad mo dyan putangina kang siraulo kang mongoloid pilot dyan airport ila beses bang sabi interested rabaho airport mo restaurant mo putangina mo gawin mong reachable website 247 tangina",
                  "['ano', 'nililipad', 'mo', 'dyan', 'putangina', 'kang', 'siraulo', 'kang', 'mongoloid', 'pilot', 'dyan', 'airport', 'ila', 'beses', 'bang', 'sabi', 'interested', 'rabaho', 'airport', 'mo', 'restaurant', 'mo', 'putangina', 'mo', 'gawin', 'mong', 'reachable', 'website', '247', 'tangina']",
                  "ano nililipad mo dyan putangina kang siraulo kang mongoloid pilot dyan airport ila beses bang sabi interested rabaho airport mo restaurant mo putangina mo gawin mong reachable website 247 tangina"
                ],
                [
                  "4",
                  "The neighbor's smell got in the condo pota amoy bumbay",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "neighbor smell got condo pota amoy bumbay",
                  "['neighbor', 'smell', 'got', 'condo', 'pota', 'amoy', 'bumbay']",
                  "neighbor smell got condo pota amoy bumbay"
                ],
                [
                  "5",
                  "TANGINA PORKET 13 LANG AKO GANYAN NA KAYO SAKEN HAYS MAGBBIRHTDAY DIN KASI AKO WEYT NYO LANG PAKYU GURANG NA KASI KAYO EH",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "tangina porket 13 lang ganyan kayo saken hay magbbirhtday kasi weyt nyo lang pakyu gurang kasi kayo eh",
                  "['tangina', 'porket', '13', 'lang', 'ganyan', 'kayo', 'saken', 'hay', 'magbbirhtday', 'kasi', 'weyt', 'nyo', 'lang', 'pakyu', 'gurang', 'kasi', 'kayo', 'eh']",
                  "tangina porket 13 lang ganyan kayo saken hay magbbirhtday kasi weyt nyo lang pakyu gurang kasi kayo eh"
                ],
                [
                  "6",
                  "Bobo kaba, dito ako nakatira mga kaklase finafillow ako, paano nila maiintindihan pinagsasabi ko pag tinagalog bobo talaga mga pinoy napaka tanga",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "bobo kaba tira lase finafillow intindi sabi pag tinagalog bobo talaga pinoy tanga",
                  "['bobo', 'kaba', 'tira', 'lase', 'finafillow', 'intindi', 'sabi', 'pag', 'tinagalog', 'bobo', 'talaga', 'pinoy', 'tanga']",
                  "bobo kaba tira lase finafillow intindi sabi pag tinagalog bobo talaga pinoy tanga"
                ],
                [
                  "7",
                  "And for the nth time, yawa ang mga lalaki period no erase ulol pakyu.",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "nth time yawa laki period erase ulol pakyu",
                  "['nth', 'time', 'yawa', 'laki', 'period', 'erase', 'ulol', 'pakyu']",
                  "nth time yawa laki period erase ulol pakyu"
                ],
                [
                  "8",
                  "CATHOLICS FUCK YALL FOR DRAGGING THE PURA LUKA ISSUE GANYAN BA YUNG MGA SINASAMBA NYONG DYOS-DYOSAN? YALL R SO HAPPY FOR OTHER'S SUFFERING SO FUCK YALL",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "catholic fuck yall dragging pura luka issue ganyan ba yung samba nyong dyosdyosan yall r happy others suffering fuck yall",
                  "['catholic', 'fuck', 'yall', 'dragging', 'pura', 'luka', 'issue', 'ganyan', 'ba', 'yung', 'samba', 'nyong', 'dyosdyosan', 'yall', 'r', 'happy', 'others', 'suffering', 'fuck', 'yall']",
                  "catholic fuck yall dragging pura luka issue ganyan ba yung samba nyong dyosdyosan yall r happy others suffering fuck yall"
                ],
                [
                  "9",
                  "tangIna faggot kang anak ng pating kang abnoy ka na pisteng ulol ah fucking bitch giatay kang burikat ka na mukang ebak na puno ng kinginamong hayop ka ampanget ng nanay mo ampanget ng tatay mo syempre dika exempted panget ka din tangina mo",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "tangina faggot kang anak pati kang abnoy pisteng ulol ah fucking bitch giatay kang burikat mukang ebak puno kinginamong hayop ampanget nanay mo ampanget tatay mo yempre dika exempted panget tangina mo",
                  "['tangina', 'faggot', 'kang', 'anak', 'pati', 'kang', 'abnoy', 'pisteng', 'ulol', 'ah', 'fucking', 'bitch', 'giatay', 'kang', 'burikat', 'mukang', 'ebak', 'puno', 'kinginamong', 'hayop', 'ampanget', 'nanay', 'mo', 'ampanget', 'tatay', 'mo', 'yempre', 'dika', 'exempted', 'panget', 'tangina', 'mo']",
                  "tangina faggot kang anak pati kang abnoy pisteng ulol ah fucking bitch giatay kang burikat mukang ebak puno kinginamong hayop ampanget nanay mo ampanget tatay mo yempre dika exempted panget tangina mo"
                ],
                [
                  "10",
                  "Mga lalaki talaga mga hayuk sa babae. Tangina. Kakapanood niyo kasi ng pornography videos na pinagsasabay ang mga babae. Mga putangina niyong mga manloloko kayo. Kating kati?",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "laki talaga hayuk babae tangina kakapanood niyo kasi pornography video pinagsasabay babae putangina niyo loko kayo kating kati",
                  "['laki', 'talaga', 'hayuk', 'babae', 'tangina', 'kakapanood', 'niyo', 'kasi', 'pornography', 'video', 'pinagsasabay', 'babae', 'putangina', 'niyo', 'loko', 'kayo', 'kating', 'kati']",
                  "laki talaga hayuk babae tangina kakapanood niyo kasi pornography video pinagsasabay babae putangina niyo loko kayo kating kati"
                ],
                [
                  "11",
                  "Putangina pwede bang itigil na ng matatanda mag sabi ng kababae mong tao ganyan ka like shut the fuck up i didn't ask for your opinion nobody needs your stupid opinion pag babae ka you're supposed to be the taga linis kase you're babae pag lalake ka it's okay -",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "putangina wede bang tigil tanda mag kababae mong tao ganyan like shut fuck didnt ask opinion nobody need stupid opinion pag babae youre supposed taga linis kase youre babae pag lake okay",
                  "['putangina', 'wede', 'bang', 'tigil', 'tanda', 'mag', 'kababae', 'mong', 'tao', 'ganyan', 'like', 'shut', 'fuck', 'didnt', 'ask', 'opinion', 'nobody', 'need', 'stupid', 'opinion', 'pag', 'babae', 'youre', 'supposed', 'taga', 'linis', 'kase', 'youre', 'babae', 'pag', 'lake', 'okay']",
                  "putangina wede bang tigil tanda mag kababae mong tao ganyan like shut fuck didnt ask opinion nobody need stupid opinion pag babae youre supposed taga linis kase youre babae pag lake okay"
                ],
                [
                  "12",
                  "mamatay na sana yung sumaksak sa aso ko, pupulutanin nyo kasi malaki katawan? di payatot noh, alagang alaga eh. mamatay na kayo pls!!!!! putang ina nyo di nyo deserve mabuhay, kayo yung hayop dito.",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "matay sana yung sumaksak aso pupulutanin nyo kasi laki tawan di yatot noh alaga alaga eh matay kayo pls puta ina nyo di nyo deserve buhay kayo yung hayop",
                  "['matay', 'sana', 'yung', 'sumaksak', 'aso', 'pupulutanin', 'nyo', 'kasi', 'laki', 'tawan', 'di', 'yatot', 'noh', 'alaga', 'alaga', 'eh', 'matay', 'kayo', 'pls', 'puta', 'ina', 'nyo', 'di', 'nyo', 'deserve', 'buhay', 'kayo', 'yung', 'hayop']",
                  "matay sana yung sumaksak aso pupulutanin nyo kasi laki tawan di yatot noh alaga alaga eh matay kayo pls puta ina nyo di nyo deserve buhay kayo yung hayop"
                ],
                [
                  "13",
                  "when will ppl understand that, just increasing the volume doesnt equate to sounding good, fuck man nakakapikon tunog dito sa church ansakit sa tenga amputa",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "ppl understand increasing volume doesnt equate sounding good fuck man pikon tunog church ansakit tenga amputa",
                  "['ppl', 'understand', 'increasing', 'volume', 'doesnt', 'equate', 'sounding', 'good', 'fuck', 'man', 'pikon', 'tunog', 'church', 'ansakit', 'tenga', 'amputa']",
                  "ppl understand increasing volume doesnt equate sounding good fuck man pikon tunog church ansakit tenga amputa"
                ],
                [
                  "14",
                  "fuck you and your twisted beliefs. mas genuine pa yung sympathy ng chaplain sa evangelical church ng tabak putangina niyo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "fuck twisted belief mas genuine yung sympathy chaplain evangelical church tabak putangina niyo",
                  "['fuck', 'twisted', 'belief', 'mas', 'genuine', 'yung', 'sympathy', 'chaplain', 'evangelical', 'church', 'tabak', 'putangina', 'niyo']",
                  "fuck twisted belief mas genuine yung sympathy chaplain evangelical church tabak putangina niyo"
                ],
                [
                  "15",
                  "anong gusto mo? sagutin kita? e may jowa ako lol. tanginamo, ante. baliw ka ba???? educ pa naman course mo, tapos ganyan ka. yawa ang bobo mo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "ano mo sagot kita e jowa lol tanginamo ante baliw ba educ naman course mo tapos ganyan yawa bobo mo",
                  "['ano', 'mo', 'sagot', 'kita', 'e', 'jowa', 'lol', 'tanginamo', 'ante', 'baliw', 'ba', 'educ', 'naman', 'course', 'mo', 'tapos', 'ganyan', 'yawa', 'bobo', 'mo']",
                  "ano mo sagot kita e jowa lol tanginamo ante baliw ba educ naman course mo tapos ganyan yawa bobo mo"
                ],
                [
                  "16",
                  "isasama ko kayo sa mga badjao, mga ulol pinagiisipan niyo ako ng masama wag po ako awa na hahahahaha gago",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "sama kayo badjao ulol pinagiisipan niyo sama wag po awa hahahahaha gago",
                  "['sama', 'kayo', 'badjao', 'ulol', 'pinagiisipan', 'niyo', 'sama', 'wag', 'po', 'awa', 'hahahahaha', 'gago']",
                  "sama kayo badjao ulol pinagiisipan niyo sama wag po awa hahahahaha gago"
                ],
                [
                  "17",
                  "bobo ka na pari niluluto yan sa lunch counter ng mga public school kupal ipinamimigay yan tuwing recess ng hapon leader ako noon sa room kaya ako ang taga kuha submit sa lunch counter yung present during that time at tatawagin kapag ready na saan ka ba nagaral noon sa gay bar",
                  "0",
                  "1",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "bobo pari luto yan lunch counter public school kupal migay yan tuwi recess hapon leader room taga kuha submit lunch counter yung present time tawag ready ba nagaral gay bar",
                  "['bobo', 'pari', 'luto', 'yan', 'lunch', 'counter', 'public', 'school', 'kupal', 'migay', 'yan', 'tuwi', 'recess', 'hapon', 'leader', 'room', 'taga', 'kuha', 'submit', 'lunch', 'counter', 'yung', 'present', 'time', 'tawag', 'ready', 'ba', 'nagaral', 'gay', 'bar']",
                  "bobo pari luto yan lunch counter public school kupal migay yan tuwi recess hapon leader room taga kuha submit lunch counter yung present time tawag ready ba nagaral gay bar"
                ],
                [
                  "18",
                  "kadiri sa feeling educated sa fb tapos kunwari palaging tama,, bugok, panget ka na nga, kinulang ka pa sa height, asim mo pa!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "kadiri feeling educated fb tapos kunwari lagi tama bugok panget nga kinulang height asim mo",
                  "['kadiri', 'feeling', 'educated', 'fb', 'tapos', 'kunwari', 'lagi', 'tama', 'bugok', 'panget', 'nga', 'kinulang', 'height', 'asim', 'mo']",
                  "kadiri feeling educated fb tapos kunwari lagi tama bugok panget nga kinulang height asim mo"
                ],
                [
                  "19",
                  "TANGINA NG ADMIN NA TO PUTA RECORDED NA NGA YUNG SOEECH NAPAKATAGAL PA IEDIT MGA PUTANGINANG WALANGHIYA, I-LIVESTREAM NIYO NA LANG NG BUO KAHIT ILANG ORAS YAN GANUN DIN NAMAN WALANG KWENTA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "tangina admin puta recorded nga yung soeech tagal iedit putanginang walanghiya ilivestream niyo lang buo ila oras yan ganon naman wenta",
                  "['tangina', 'admin', 'puta', 'recorded', 'nga', 'yung', 'soeech', 'tagal', 'iedit', 'putanginang', 'walanghiya', 'ilivestream', 'niyo', 'lang', 'buo', 'ila', 'oras', 'yan', 'ganon', 'naman', 'wenta']",
                  "tangina admin puta recorded nga yung soeech tagal iedit putanginang walanghiya ilivestream niyo lang buo ila oras yan ganon naman wenta"
                ],
                [
                  "20",
                  "these filipinos knew damn well how to milk us like yall monkeys should stop migrating here smh",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "filipino knew damn well milk u like yall monkey stop migrating smh",
                  "['filipino', 'knew', 'damn', 'well', 'milk', 'u', 'like', 'yall', 'monkey', 'stop', 'migrating', 'smh']",
                  "filipino knew damn well milk u like yall monkey stop migrating smh"
                ],
                [
                  "21",
                  "Bakit ba ang bobobobo ng mga baby boomers na naka-upo??? Keep up naman mga tanda. Tangina naman nauuumay na kong panuorin kayong mamahala. Nakakawala ng respeto. Pakshit kayo.",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "ba bobobobo baby boomer upo keep naman tanda tangina naman nauuumay panuorin kayo mahala wala respeto pakshit kayo",
                  "['ba', 'bobobobo', 'baby', 'boomer', 'upo', 'keep', 'naman', 'tanda', 'tangina', 'naman', 'nauuumay', 'panuorin', 'kayo', 'mahala', 'wala', 'respeto', 'pakshit', 'kayo']",
                  "ba bobobobo baby boomer upo keep naman tanda tangina naman nauuumay panuorin kayo mahala wala respeto pakshit kayo"
                ],
                [
                  "22",
                  "BOBO SURE AKO NA BY NOW IKINAHIHIYA KA NG MGA TITSER AT KAMG ANAK MO SA KABOBOHAN MO MAG KOMENTO. ANG TANGA TANGA KASI",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "bobo sure hiya titsed kamg anak mo kabobohan mo mag komento tanga tanga kasi",
                  "['bobo', 'sure', 'hiya', 'titsed', 'kamg', 'anak', 'mo', 'kabobohan', 'mo', 'mag', 'komento', 'tanga', 'tanga', 'kasi']",
                  "bobo sure hiya titsed kamg anak mo kabobohan mo mag komento tanga tanga kasi"
                ],
                [
                  "23",
                  "hindi naman ako lalaki para gawin yun tangina gusto ko rin maranasan yon ng kinukusa",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "naman laki gawin yun tangina rin ranas yon kinukusa",
                  "['naman', 'laki', 'gawin', 'yun', 'tangina', 'rin', 'ranas', 'yon', 'kinukusa']",
                  "naman laki gawin yun tangina rin ranas yon kinukusa"
                ],
                [
                  "24",
                  "taena haha kung ano ano pang sinasabi tapos ligwak naman pala sa dl/pl this sem. Bobo HAHA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "taena haha pang sabi tapos ligwak naman pala dlpl sem bobo haha",
                  "['taena', 'haha', 'pang', 'sabi', 'tapos', 'ligwak', 'naman', 'pala', 'dlpl', 'sem', 'bobo', 'haha']",
                  "taena haha pang sabi tapos ligwak naman pala dlpl sem bobo haha"
                ],
                [
                  "25",
                  "TANGINA NI GADGET ADDICT, WALA NANG NAIDULOT KUNG HINDI PURO INTRIGA AT SCANDAL",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "tangina gadget addict wala nang naidulot puro riga scandal",
                  "['tangina', 'gadget', 'addict', 'wala', 'nang', 'naidulot', 'puro', 'riga', 'scandal']",
                  "tangina gadget addict wala nang naidulot puro riga scandal"
                ],
                [
                  "26",
                  "ulol bakla mamatay kana sama mo amo mo",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "ulol bakla matay kana sama mo amo mo",
                  "['ulol', 'bakla', 'matay', 'kana', 'sama', 'mo', 'amo', 'mo']",
                  "ulol bakla matay kana sama mo amo mo"
                ],
                [
                  "27",
                  "Pag supporter talaga ni Deputa tanga, inutil, imbecile, walang dulot ang sinasabi, ignorante, lahat na masasamang words pwede na sabihin. Binadmouth ko talaga haha wala 'kong pake kung matanda ka sa'kin",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "pag supporter talaga deputa tanga util imbecile dulot sabi ignorante sama word wede binadmouth talaga haha wala pake tanda sakin",
                  "['pag', 'supporter', 'talaga', 'deputa', 'tanga', 'util', 'imbecile', 'dulot', 'sabi', 'ignorante', 'sama', 'word', 'wede', 'binadmouth', 'talaga', 'haha', 'wala', 'pake', 'tanda', 'sakin']",
                  "pag supporter talaga deputa tanga util imbecile dulot sabi ignorante sama word wede binadmouth talaga haha wala pake tanda sakin"
                ],
                [
                  "28",
                  "Eng prof men matanda na, sana gahasain siya ng bakla",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "eng prof men tanda sana gahasain bakla",
                  "['eng', 'prof', 'men', 'tanda', 'sana', 'gahasain', 'bakla']",
                  "eng prof men tanda sana gahasain bakla"
                ],
                [
                  "29",
                  "ALA AKONG PAKE SA PERA MO GIRL MAY SARILI AKONG BUHAY ATLIS WALA AKONG SUGAR DADDY BOBO HAYOP NATO TANGINA NAKAILANG ARABO KANA DYAN SA IBANG BANSA TARATANDO KA HAHAHA INIWAN YUNG ASAWA PARA SA ARABO PABUNTIS KA DYAN BE PARA YUMAMAN KA",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "ala ako pake pera mo girl ako buhay atlis wala ako sugar daddy bobo hayop nato tangina nakailang arabo kana dyan iba bansa taratando haha iwan yung asawa arabo pabuntis dyan yaman",
                  "['ala', 'ako', 'pake', 'pera', 'mo', 'girl', 'ako', 'buhay', 'atlis', 'wala', 'ako', 'sugar', 'daddy', 'bobo', 'hayop', 'nato', 'tangina', 'nakailang', 'arabo', 'kana', 'dyan', 'iba', 'bansa', 'taratando', 'haha', 'iwan', 'yung', 'asawa', 'arabo', 'pabuntis', 'dyan', 'yaman']",
                  "ala ako pake pera mo girl ako buhay atlis wala ako sugar daddy bobo hayop nato tangina nakailang arabo kana dyan iba bansa taratando haha iwan yung asawa arabo pabuntis dyan yaman"
                ],
                [
                  "30",
                  "kanina may nakasalubong ako sa elevator mabaho ughhhhhhhhh. amoy putok ng bumbay + dying animals. natrauma na ako sa elevator",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "nina salubo elevator baho ughhhhhhhhh amoy putok bumbay dying animal natrauma elevator",
                  "['nina', 'salubo', 'elevator', 'baho', 'ughhhhhhhhh', 'amoy', 'putok', 'bumbay', 'dying', 'animal', 'natrauma', 'elevator']",
                  "nina salubo elevator baho ughhhhhhhhh amoy putok bumbay dying animal natrauma elevator"
                ],
                [
                  "31",
                  "Gago ang pangit nyo talaga kayong matatanda na walang pagkatandaan. Boomer energy ampota",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "gago pangit nyo talaga kayo tanda pagkatandaan boomer energy ampota",
                  "['gago', 'pangit', 'nyo', 'talaga', 'kayo', 'tanda', 'pagkatandaan', 'boomer', 'energy', 'ampota']",
                  "gago pangit nyo talaga kayo tanda pagkatandaan boomer energy ampota"
                ],
                [
                  "32",
                  "hindot na binabae pa.... ngiwi dito ngiwi dun... hahaha",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "hindot binabae ngiwi ngiwi dun haha",
                  "['hindot', 'binabae', 'ngiwi', 'ngiwi', 'dun', 'haha']",
                  "hindot binabae ngiwi ngiwi dun haha"
                ],
                [
                  "33",
                  "Nang gigil nanaman si ako sa mga teenager na to kung mag ano sus. Mga pakyu!",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "nang gigil naman si teenager mag sus pakyu",
                  "['nang', 'gigil', 'naman', 'si', 'teenager', 'mag', 'sus', 'pakyu']",
                  "nang gigil naman si teenager mag sus pakyu"
                ],
                [
                  "34",
                  "Hay ang ganda namang bungad sa umaga. Parang makakasapak ako ng intsik mamaya",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "hay ganda nama bungad aga para makakasapak intsik maya",
                  "['hay', 'ganda', 'nama', 'bungad', 'aga', 'para', 'makakasapak', 'intsik', 'maya']",
                  "hay ganda nama bungad aga para makakasapak intsik maya"
                ],
                [
                  "35",
                  "etong mga madre na mga puta na sumusuporta kay lenitard putangina nyo",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "etong madre puta suporta kay lenitard putangina nyo",
                  "['etong', 'madre', 'puta', 'suporta', 'kay', 'lenitard', 'putangina', 'nyo']",
                  "etong madre puta suporta kay lenitard putangina nyo"
                ],
                [
                  "36",
                  "all priests are fucking predators tangina nyong mga puta kayo fucking die in hell",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "priest fucking predator tangina nyong puta kayo fucking die hell",
                  "['priest', 'fucking', 'predator', 'tangina', 'nyong', 'puta', 'kayo', 'fucking', 'die', 'hell']",
                  "priest fucking predator tangina nyong puta kayo fucking die hell"
                ],
                [
                  "37",
                  "Tapos dinpa inallow ung testing center sa Marikina. Pakyu Duque! Magresign ka na po! Isa kang corrupt BOOMER!",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "tapos dinpa inallow ung testing center marikina pakyu duque magresign po kang corrupt boomer",
                  "['tapos', 'dinpa', 'inallow', 'ung', 'testing', 'center', 'marikina', 'pakyu', 'duque', 'magresign', 'po', 'kang', 'corrupt', 'boomer']",
                  "tapos dinpa inallow ung testing center marikina pakyu duque magresign po kang corrupt boomer"
                ],
                [
                  "38",
                  "Nakalimutan na naman uminom ng gamot si Tanda! Hoy GAGO mag kulambo ka na lang. You are not relevant anymore.",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "limot naman inom gamot si tanda hoy gago mag kulambo lang relevant anymore",
                  "['limot', 'naman', 'inom', 'gamot', 'si', 'tanda', 'hoy', 'gago', 'mag', 'kulambo', 'lang', 'relevant', 'anymore']",
                  "limot naman inom gamot si tanda hoy gago mag kulambo lang relevant anymore"
                ],
                [
                  "39",
                  "Ulol. Basta Iglesia talaga bobo.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "ulol basta iglesia talaga bobo",
                  "['ulol', 'basta', 'iglesia', 'talaga', 'bobo']",
                  "ulol basta iglesia talaga bobo"
                ],
                [
                  "40",
                  "Ganon ba dapat mag-act ang isang madre? :/ #MMK\" onga. Sarap patayin eh. HAHAHA. XD",
                  "0",
                  "0",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "ganon ba magact madre mmk onga sarap tayin eh haha xd",
                  "['ganon', 'ba', 'magact', 'madre', 'mmk', 'onga', 'sarap', 'tayin', 'eh', 'haha', 'xd']",
                  "ganon ba magact madre mmk onga sarap tayin eh haha xd"
                ],
                [
                  "41",
                  "uy gago sakit naman lalo na yung ending niyan bwiset yung bata diyan eh",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "uy gago sakit naman lalo yung ending niyan bwiset yung bata diyan eh",
                  "['uy', 'gago', 'sakit', 'naman', 'lalo', 'yung', 'ending', 'niyan', 'bwiset', 'yung', 'bata', 'diyan', 'eh']",
                  "uy gago sakit naman lalo yung ending niyan bwiset yung bata diyan eh"
                ],
                [
                  "42",
                  "Maka millenials naman tong nanay ko eh sarap sabunutan eh.",
                  "1",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "maka millenials naman tong nanay eh sarap sabunutan eh",
                  "['maka', 'millenials', 'naman', 'tong', 'nanay', 'eh', 'sarap', 'sabunutan', 'eh']",
                  "maka millenials naman tong nanay eh sarap sabunutan eh"
                ],
                [
                  "43",
                  "TAPOS TANGINA KANG MONGOLOID PILOT KA, GAANO PA KABAGAL ANG PAGCHI-CHECK MO NG BOX NG reCAPTCHA KUNG HINDI NAMAN AKO PUPUNTA SA PASIG, MALABON AND MANDALUYONG BRANCHES? HINDI RIN AKO MAGTATRABAHO SA AIRPORT MO OR SA RESTAURANT MO PUTANGINA MO MONGOLOID PILOT. I'LL TEACH TANGINA.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "tapos tangina kang mongoloid pilot gaano kabagal pagchicheck mo box recaptcha naman punta pasig malabon mandaluyong branch rin tatrabaho airport mo restaurant mo putangina mo mongoloid pilot ill teach tangina",
                  "['tapos', 'tangina', 'kang', 'mongoloid', 'pilot', 'gaano', 'kabagal', 'pagchicheck', 'mo', 'box', 'recaptcha', 'naman', 'punta', 'pasig', 'malabon', 'mandaluyong', 'branch', 'rin', 'tatrabaho', 'airport', 'mo', 'restaurant', 'mo', 'putangina', 'mo', 'mongoloid', 'pilot', 'ill', 'teach', 'tangina']",
                  "tapos tangina kang mongoloid pilot gaano kabagal pagchicheck mo box recaptcha naman punta pasig malabon mandaluyong branch rin tatrabaho airport mo restaurant mo putangina mo mongoloid pilot ill teach tangina"
                ],
                [
                  "44",
                  "may galit talaga ako sa mga iglesia eh. tangina kasi nila. AHAHAHAHA",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "galit talaga iglesia eh tangina kasi ahahahaha",
                  "['galit', 'talaga', 'iglesia', 'eh', 'tangina', 'kasi', 'ahahahaha']",
                  "galit talaga iglesia eh tangina kasi ahahahaha"
                ],
                [
                  "45",
                  "hahhahaha mga putanginang bobong bulag n mga suporter to! gutom n sinasampal n ng ktutuhanan mga incompetent bnoto nila tanga tangahan parin!",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "1",
                  "0",
                  "hahhahaha putanginang bobong bulag n suporter gutom n sinasampal n ktutuhanan incompetent bnoto tanga tangahan parin",
                  "['hahhahaha', 'putanginang', 'bobong', 'bulag', 'n', 'suporter', 'gutom', 'n', 'sinasampal', 'n', 'ktutuhanan', 'incompetent', 'bnoto', 'tanga', 'tangahan', 'parin']",
                  "hahhahaha putanginang bobong bulag n suporter gutom n sinasampal n ktutuhanan incompetent bnoto tanga tangahan parin"
                ],
                [
                  "46",
                  "Ang bastos talaga ng ibang baby boomers tangina, ang lumanay ng tono ko sakaniya bigla ba naman akong sabihan ng bastos??",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "bastos talaga iba baby boomer tangina lumanay tono sakaniya bigla ba naman ako sabi bastos",
                  "['bastos', 'talaga', 'iba', 'baby', 'boomer', 'tangina', 'lumanay', 'tono', 'sakaniya', 'bigla', 'ba', 'naman', 'ako', 'sabi', 'bastos']",
                  "bastos talaga iba baby boomer tangina lumanay tono sakaniya bigla ba naman ako sabi bastos"
                ],
                [
                  "47",
                  "You're such a pity thou like why allowing yourself to be that low, tanga tangahan si tanda for free",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "youre pity thou like allowing low tanga tangahan si tanda free",
                  "['youre', 'pity', 'thou', 'like', 'allowing', 'low', 'tanga', 'tangahan', 'si', 'tanda', 'free']",
                  "youre pity thou like allowing low tanga tangahan si tanda free"
                ],
                [
                  "48",
                  "DI KO NILALAHAT AH! PERO TRIGGERED NA TRIEGGERED NA TALAGA AKO EH! S/O SA MGA IMMA FANS JAN NA HALOS LAHAT MGA BABY BRA WARRIORS!! TANGINA NYO AH KUNG WALA KAYONG MAGANDANG MASABI MANAHIMIK NALANG KAYO PWEDE? NAKAKAHIYA KAYO EH! MADAMING MEANING ANG BTS FYI WAG KAYONG MEMA!",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "di nilalahat ah triggered trieggered talaga eh imma fan jan halos baby bra warrior tangina nyo ah wala kayo anda sabi ahimik nala kayo wede hiya kayo eh dami meaning bts fyi wag kayo mema",
                  "['di', 'nilalahat', 'ah', 'triggered', 'trieggered', 'talaga', 'eh', 'imma', 'fan', 'jan', 'halos', 'baby', 'bra', 'warrior', 'tangina', 'nyo', 'ah', 'wala', 'kayo', 'anda', 'sabi', 'ahimik', 'nala', 'kayo', 'wede', 'hiya', 'kayo', 'eh', 'dami', 'meaning', 'bts', 'fyi', 'wag', 'kayo', 'mema']",
                  "di nilalahat ah triggered trieggered talaga eh imma fan jan halos baby bra warrior tangina nyo ah wala kayo anda sabi ahimik nala kayo wede hiya kayo eh dami meaning bts fyi wag kayo mema"
                ],
                [
                  "49",
                  "Mag oopinion ka na nga lang mali mali pa bobo ka wala ka masabeng matino utak talangka",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "mag oopinion nga lang mali mali bobo wala masabeng tino utak talangka",
                  "['mag', 'oopinion', 'nga', 'lang', 'mali', 'mali', 'bobo', 'wala', 'masabeng', 'tino', 'utak', 'talangka']",
                  "mag oopinion nga lang mali mali bobo wala masabeng tino utak talangka"
                ]
              ],
              "shape": {
                "columns": 11,
                "rows": 4343
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Physical</th>\n",
              "      <th>Race</th>\n",
              "      <th>Religion</th>\n",
              "      <th>Politics</th>\n",
              "      <th>Others</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>token_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tangina Chinese. Pinapasakop naman tayo ng isa...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>tangina chinese pinapasakop naman tangatangang...</td>\n",
              "      <td>[tangina, chinese, pinapasakop, naman, tangata...</td>\n",
              "      <td>tangina chinese pinapasakop naman tangatangang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ay bakit?porke ba nasa America ka ay di ka na ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bakitporke ba nasa america di pinoyulol magpab...</td>\n",
              "      <td>[bakitporke, ba, nasa, america, di, pinoyulol,...</td>\n",
              "      <td>bakitporke ba nasa america di pinoyulol magpab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ano ba kasing pinaglalaban ng mga Iglesia sa E...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ba kasi laban iglesia edsa gulo nga dun dagan ...</td>\n",
              "      <td>[ba, kasi, laban, iglesia, edsa, gulo, nga, du...</td>\n",
              "      <td>ba kasi laban iglesia edsa gulo nga dun dagan ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Anong nililipad mo dyan PUTANGINA KANG SIRAULO...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>ano nililipad mo dyan putangina kang siraulo k...</td>\n",
              "      <td>[ano, nililipad, mo, dyan, putangina, kang, si...</td>\n",
              "      <td>ano nililipad mo dyan putangina kang siraulo k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The neighbor's smell got in the condo pota amo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>neighbor smell got condo pota amoy bumbay</td>\n",
              "      <td>[neighbor, smell, got, condo, pota, amoy, bumbay]</td>\n",
              "      <td>neighbor smell got condo pota amoy bumbay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4338</th>\n",
              "      <td>Ang bagal ng serbisyo kasi puro matatanda ang ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>bagal serbisyo kasi puro tanda tatrabaho</td>\n",
              "      <td>[bagal, serbisyo, kasi, puro, tanda, tatrabaho]</td>\n",
              "      <td>bagal serbisyo kasi puro tanda tatrabaho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4339</th>\n",
              "      <td>Wala nang naitulong 'yang mga gurang na 'yan, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>wala nang itulo yang gurang yan puro sakit lang</td>\n",
              "      <td>[wala, nang, itulo, yang, gurang, yan, puro, s...</td>\n",
              "      <td>wala nang itulo yang gurang yan puro sakit lang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4340</th>\n",
              "      <td>Mga Gen Z, puro lang salita, wala namang gawa.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>gen z puro lang salita wala nama gawa</td>\n",
              "      <td>[gen, z, puro, lang, salita, wala, nama, gawa]</td>\n",
              "      <td>gen z puro lang salita wala nama gawa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4341</th>\n",
              "      <td>Sana mawala na sa sistema 'yang mga tanda na '...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sana wala sistema yang tanda yan bago</td>\n",
              "      <td>[sana, wala, sistema, yang, tanda, yan, bago]</td>\n",
              "      <td>sana wala sistema yang tanda yan bago</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4342</th>\n",
              "      <td>Hindi na nakakasabay sa uso ang mga matatanda,...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>nakakasabay uso tanda panay pangit anamit</td>\n",
              "      <td>[nakakasabay, uso, tanda, panay, pangit, anamit]</td>\n",
              "      <td>nakakasabay uso tanda panay pangit anamit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4343 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Age  Gender  \\\n",
              "0     Tangina Chinese. Pinapasakop naman tayo ng isa...    0       0   \n",
              "1     ay bakit?porke ba nasa America ka ay di ka na ...    0       0   \n",
              "2     Ano ba kasing pinaglalaban ng mga Iglesia sa E...    0       0   \n",
              "3     Anong nililipad mo dyan PUTANGINA KANG SIRAULO...    0       0   \n",
              "4     The neighbor's smell got in the condo pota amo...    0       0   \n",
              "...                                                 ...  ...     ...   \n",
              "4338  Ang bagal ng serbisyo kasi puro matatanda ang ...    1       0   \n",
              "4339  Wala nang naitulong 'yang mga gurang na 'yan, ...    1       0   \n",
              "4340     Mga Gen Z, puro lang salita, wala namang gawa.    1       0   \n",
              "4341  Sana mawala na sa sistema 'yang mga tanda na '...    1       0   \n",
              "4342  Hindi na nakakasabay sa uso ang mga matatanda,...    1       0   \n",
              "\n",
              "      Physical  Race  Religion  Politics  Others  \\\n",
              "0            0     1         0         1       0   \n",
              "1            0     1         0         0       0   \n",
              "2            0     0         1         0       0   \n",
              "3            1     0         0         0       0   \n",
              "4            1     1         0         0       0   \n",
              "...        ...   ...       ...       ...     ...   \n",
              "4338         0     0         0         0       0   \n",
              "4339         0     0         0         0       0   \n",
              "4340         0     0         0         0       0   \n",
              "4341         0     0         0         0       0   \n",
              "4342         0     0         0         0       0   \n",
              "\n",
              "                                             clean_text  \\\n",
              "0     tangina chinese pinapasakop naman tangatangang...   \n",
              "1     bakitporke ba nasa america di pinoyulol magpab...   \n",
              "2     ba kasi laban iglesia edsa gulo nga dun dagan ...   \n",
              "3     ano nililipad mo dyan putangina kang siraulo k...   \n",
              "4             neighbor smell got condo pota amoy bumbay   \n",
              "...                                                 ...   \n",
              "4338           bagal serbisyo kasi puro tanda tatrabaho   \n",
              "4339    wala nang itulo yang gurang yan puro sakit lang   \n",
              "4340              gen z puro lang salita wala nama gawa   \n",
              "4341              sana wala sistema yang tanda yan bago   \n",
              "4342          nakakasabay uso tanda panay pangit anamit   \n",
              "\n",
              "                                                 tokens  \\\n",
              "0     [tangina, chinese, pinapasakop, naman, tangata...   \n",
              "1     [bakitporke, ba, nasa, america, di, pinoyulol,...   \n",
              "2     [ba, kasi, laban, iglesia, edsa, gulo, nga, du...   \n",
              "3     [ano, nililipad, mo, dyan, putangina, kang, si...   \n",
              "4     [neighbor, smell, got, condo, pota, amoy, bumbay]   \n",
              "...                                                 ...   \n",
              "4338    [bagal, serbisyo, kasi, puro, tanda, tatrabaho]   \n",
              "4339  [wala, nang, itulo, yang, gurang, yan, puro, s...   \n",
              "4340     [gen, z, puro, lang, salita, wala, nama, gawa]   \n",
              "4341      [sana, wala, sistema, yang, tanda, yan, bago]   \n",
              "4342   [nakakasabay, uso, tanda, panay, pangit, anamit]   \n",
              "\n",
              "                                             token_text  \n",
              "0     tangina chinese pinapasakop naman tangatangang...  \n",
              "1     bakitporke ba nasa america di pinoyulol magpab...  \n",
              "2     ba kasi laban iglesia edsa gulo nga dun dagan ...  \n",
              "3     ano nililipad mo dyan putangina kang siraulo k...  \n",
              "4             neighbor smell got condo pota amoy bumbay  \n",
              "...                                                 ...  \n",
              "4338           bagal serbisyo kasi puro tanda tatrabaho  \n",
              "4339    wala nang itulo yang gurang yan puro sakit lang  \n",
              "4340              gen z puro lang salita wala nama gawa  \n",
              "4341              sana wala sistema yang tanda yan bago  \n",
              "4342          nakakasabay uso tanda panay pangit anamit  \n",
              "\n",
              "[4343 rows x 11 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hskAQvTpdq6B",
        "outputId": "d627f5b1-ce4e-43b8-fc24-f78a46a32993"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    tokenizer=tokenize,\n",
        "    max_features=MAX_FEATS,\n",
        "    ngram_range=NGRAM_RANGE,\n",
        "    lowercase=True,\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_original).astype(np.float32).toarray()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Kkj0d2etqSuk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "X_test = vectorizer.transform(X_test_original).astype(np.float32).toarray()\n",
        "X_val = vectorizer.transform(X_val_original).astype(np.float32).toarray()\n",
        "\n",
        "# normalize the features\n",
        "X_train = normalize(X_train_tfidf, norm='l2')\n",
        "X_test = normalize(X_test, norm='l2')\n",
        "X_val = normalize(X_val, norm='l2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "hUdK1_LteCdu"
      },
      "outputs": [],
      "source": [
        "class LinearSVM:\n",
        "    def __init__(self, n_features: int, C: float = 10.0, lr: float = 0.1, epochs: int = 150, seed: int = 42):\n",
        "        self.C = C\n",
        "        self.lr0 = lr\n",
        "        self.epochs = epochs\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.w = np.zeros(n_features, dtype=np.float32)\n",
        "        self.b = 0.0\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        y_signed = np.where(y > 0, 1.0, -1.0).astype(np.float32)\n",
        "        n_samples = X.shape[0]\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            indices = self.rng.permutation(n_samples)\n",
        "            eta = self.lr0 / (1 + epoch * 0.01)\n",
        "            for i in indices:\n",
        "                xi = X[i]\n",
        "                yi = y_signed[i]\n",
        "                margin = yi * (np.dot(self.w, xi) + self.b)\n",
        "                if margin < 1:\n",
        "                    self.w += eta * self.C * yi * xi  # removed decay\n",
        "                    self.b += eta * self.C * yi\n",
        "\n",
        "        # bias centering fix\n",
        "        self.b = -np.mean(X @ self.w)\n",
        "\n",
        "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
        "        return X @ self.w + self.b\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        return (self.decision_function(X) >= 0).astype(np.int8)\n",
        "\n",
        "\n",
        "class OneVsRestSVM:\n",
        "    def __init__(self, n_labels: int, n_features: int, **svm_kwargs):\n",
        "        self.n_labels = n_labels\n",
        "        self.models = [LinearSVM(n_features, **svm_kwargs) for _ in range(n_labels)]\n",
        "\n",
        "    def fit(self, X: np.ndarray, Y: np.ndarray):\n",
        "        for idx in range(self.n_labels):\n",
        "            self.models[idx].fit(X, Y[:, idx])\n",
        "\n",
        "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
        "        return np.column_stack([m.decision_function(X) for m in self.models])\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        return (self.decision_function(X) >= 0).astype(np.int8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6cZcVniZeGc-"
      },
      "outputs": [],
      "source": [
        "svm = OneVsRestSVM(\n",
        "    n_labels=len(LABEL_COLUMNS),\n",
        "    n_features=X_train_tfidf.shape[1],\n",
        "    C=1.0,\n",
        "    lr=0.01,\n",
        "    epochs=5,\n",
        ")\n",
        "svm.fit(X_train, y_train.values.astype(np.int8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OXbZwnwBeKks"
      },
      "outputs": [],
      "source": [
        "RULE_LEXICONS = {\n",
        "    \"Age\": [\"tanda\", \"boomer\", \"bata\", \"matanda\", \"gurang\", \"genz\", \"millenial\"],\n",
        "    \"Gender\": [\"bakla\", \"tomboy\", \"babae kasi\", \"bading\", \"gay\", \"lesbian\"],\n",
        "    \"Physical\": [\"pangit\", \"pandak\", \"tabatsoy\", \"baldado\"],\n",
        "    \"Race\": [\"chinese\", \"unggoy\", \"nigger\", \"chingchong\"],\n",
        "    \"Religion\": [\"iglesia\", \"muslim\", \"terrorist\", \"jihad\", \"infidel\", \"catholic\", \"pari\"],\n",
        "    \"Politics\": [\"bbm\", \"dilawan\", \"kakampink\", \"komunista\", \"presidente\", \"lugaw\"],\n",
        "    \"Others\": [\"tanga\", \"ulol\", \"gago\", \"bobo\", \"stupido\", \"putangina mo\", \"putangina\", \"tangina\"],\n",
        "}\n",
        "\n",
        "\n",
        "def rule_based_labels(cleaned_text: str, lexicons: dict, label_order: List[str]) -> List[int]:\n",
        "    labels = [0] * len(label_order)\n",
        "    for i, label in enumerate(label_order):\n",
        "        for kw in lexicons[label]:\n",
        "            if kw in cleaned_text:\n",
        "                labels[i] = 1\n",
        "                break\n",
        "    return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "msH4DW7ReOUV"
      },
      "outputs": [],
      "source": [
        "def hybrid_predict(\n",
        "    raw_texts,\n",
        "    vec,\n",
        "    model,\n",
        "    lexicons,\n",
        "    label_order,\n",
        "    thr: float = UNCERTAINTY_THRESHOLD,\n",
        "):\n",
        "    feats = vec.transform(raw_texts).astype(np.float32).toarray()\n",
        "    decisions = model.decision_function(feats)\n",
        "    ml_preds = (decisions >= 0).astype(np.int8)\n",
        "\n",
        "    final_preds = []\n",
        "    for idx, text in enumerate(raw_texts):\n",
        "        cleaned = clean_text(text)\n",
        "        rule_labels = rule_based_labels(cleaned, lexicons, label_order)\n",
        "        combined = []\n",
        "        for j in range(len(label_order)):\n",
        "            if abs(decisions[idx, j]) < thr:\n",
        "                combined.append(rule_labels[j])\n",
        "            else:\n",
        "                combined.append(int(ml_preds[idx, j]))\n",
        "        final_preds.append(combined)\n",
        "    return np.array(final_preds, dtype=np.int8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1hkMeuTheVL-"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_true, y_pred, label_names):\n",
        "    print(\"=== Classification Report ===\")\n",
        "    print(\n",
        "        classification_report(\n",
        "            y_true,\n",
        "            y_pred,\n",
        "            target_names=label_names,\n",
        "            zero_division=0,\n",
        "        )\n",
        "    )\n",
        "    print(\"Hamming Loss:\", hamming_loss(y_true, y_pred))\n",
        "    print(\"Subset Accuracy:\", accuracy_score(y_true, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEICy531r9AO",
        "outputId": "9a9369b4-5ce1-4d81-ddf8-6124968aadae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SVM-RULE BASED HYBRID PERFORMANCE \n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Age       0.85      0.94      0.90       304\n",
            "      Gender       0.74      0.89      0.80       281\n",
            "    Physical       0.59      0.65      0.61       293\n",
            "        Race       0.88      0.79      0.83       201\n",
            "    Religion       0.92      0.86      0.89       290\n",
            "    Politics       0.90      0.86      0.88       227\n",
            "      Others       0.35      0.82      0.49       310\n",
            "\n",
            "   micro avg       0.66      0.83      0.74      1906\n",
            "   macro avg       0.75      0.83      0.77      1906\n",
            "weighted avg       0.73      0.83      0.76      1906\n",
            " samples avg       0.71      0.84      0.75      1906\n",
            "\n",
            "Hamming Loss: 0.09247082031892158\n",
            "Subset Accuracy: 0.5385500575373993\n"
          ]
        }
      ],
      "source": [
        "# concatenate the original Series before vectorization\n",
        "X_combined_original = pd.concat([X_test_original, X_val_original])\n",
        "y_combined = pd.concat([y_test, y_val])\n",
        "\n",
        "# transform the combined original Series using the fitted vectorizer\n",
        "X_combined_tfidf = vectorizer.transform(X_combined_original).astype(np.float32).toarray()\n",
        "\n",
        "# normalize\n",
        "X_combined = normalize(X_combined_tfidf, norm='l2')\n",
        "\n",
        "y_combined_pred = hybrid_predict(X_combined_original.tolist(), vectorizer, svm, RULE_LEXICONS, LABEL_COLUMNS)\n",
        "print(\" SVM-RULE BASED HYBRID PERFORMANCE \")\n",
        "evaluate(y_combined.values, y_combined_pred, LABEL_COLUMNS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qXKfz8audet",
        "outputId": "60616095-22e3-4be7-d9a6-537179b9550f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Difference in decision outputs: 42666.24\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "svm1 = OneVsRestSVM(len(LABEL_COLUMNS), X_train.shape[1], C=0.1, lr=0.01, epochs=1)\n",
        "svm2 = OneVsRestSVM(len(LABEL_COLUMNS), X_train.shape[1], C=100.0, lr=10.0, epochs=50)\n",
        "\n",
        "svm1.fit(X_train, y_train.values.astype(np.int8))\n",
        "svm2.fit(X_train, y_train.values.astype(np.int8))\n",
        "\n",
        "dec1 = svm1.decision_function(X_train[:10])\n",
        "dec2 = svm2.decision_function(X_train[:10])\n",
        "\n",
        "print(\"Difference in decision outputs:\", np.abs(dec1 - dec2).sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH9sichLvBTc",
        "outputId": "10a58af0-a3ee-49cc-fde4-2a9da4165e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Age       0.70      0.96      0.81       304\n",
            "      Gender       0.65      0.96      0.78       281\n",
            "    Physical       0.41      0.85      0.55       293\n",
            "        Race       0.43      0.94      0.59       201\n",
            "    Religion       0.88      0.92      0.90       290\n",
            "    Politics       0.65      0.89      0.75       227\n",
            "      Others       0.43      0.88      0.58       310\n",
            "\n",
            "   micro avg       0.56      0.92      0.69      1906\n",
            "   macro avg       0.59      0.92      0.71      1906\n",
            "weighted avg       0.60      0.92      0.71      1906\n",
            " samples avg       0.65      0.92      0.73      1906\n",
            "\n",
            "Hamming Loss: 0.1274864376130199\n",
            "Subset Accuracy: 0.39298043728423476\n"
          ]
        }
      ],
      "source": [
        "# pure model-only prediction\n",
        "y_pred = svm.predict(X_combined)\n",
        "evaluate(y_combined.values, y_pred, LABEL_COLUMNS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_yrXoCLvHEF",
        "outputId": "6f2c8ed1-9a19-4f92-ee24-2883afdae564"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule override % per label:\n",
            "{'Age': 88.3199079401611, 'Gender': 89.93095512082854, 'Physical': 95.56962025316456, 'Race': 99.30955120828538, 'Religion': 88.60759493670885, 'Politics': 90.73647871116226, 'Others': 99.88492520138091}\n"
          ]
        }
      ],
      "source": [
        "def count_rule_usage(raw_texts, model, vectorizer, label_order, thr=0.2):\n",
        "    feats = vectorizer.transform(raw_texts).astype(np.float32).toarray()\n",
        "    decisions = model.decision_function(feats)\n",
        "    rule_used = (np.abs(decisions) < thr).astype(np.int8)\n",
        "    percent_used = rule_used.mean(axis=0) * 100\n",
        "    return dict(zip(label_order, percent_used))\n",
        "\n",
        "print(\"Rule override % per label:\")\n",
        "print(count_rule_usage(X_combined_original.tolist(), svm, vectorizer, LABEL_COLUMNS))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom SGD Classifier with regularization for comparison\n",
        "class SGD:\n",
        "    def __init__(self, n_features: int, C: float = 10.0, lr: float = 0.1, epochs: int = 150, seed: int = 42):\n",
        "        self.C = C\n",
        "        self.lr0 = lr\n",
        "        self.epochs = epochs\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.w = np.zeros(n_features, dtype=np.float32)\n",
        "        self.b = 0.0\n",
        "    \n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        y_signed = np.where(y > 0, 1.0, -1.0).astype(np.float32)\n",
        "        n_samples = X.shape[0]\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            indices = self.rng.permutation(n_samples)\n",
        "            eta = self.lr0 / (1 + epoch * 0.01)\n",
        "            for i in indices:\n",
        "                xi = X[i]\n",
        "                yi = y_signed[i]\n",
        "                margin = yi * (np.dot(self.w, xi) + self.b)\n",
        "                \n",
        "                # L2 regularization term\n",
        "                reg_term = eta / (self.C * n_samples)\n",
        "                \n",
        "                if margin < 1:\n",
        "                    # Apply regularization and hinge loss gradient\n",
        "                    self.w = (1 - reg_term) * self.w + eta * self.C * yi * xi\n",
        "                    self.b += eta * self.C * yi\n",
        "                else:\n",
        "                    # Only apply regularization\n",
        "                    self.w = (1 - reg_term) * self.w\n",
        "        \n",
        "        # bias centering fix\n",
        "        self.b = -np.mean(X @ self.w)\n",
        "\n",
        "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
        "        return X @ self.w + self.b\n",
        "    \n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        return (self.decision_function(X) >= 0).astype(np.int8)\n",
        "\n",
        "class OneVsRestSGD:\n",
        "    def __init__(self, n_labels: int, n_features: int, **sgd_kwargs):\n",
        "        self.n_labels = n_labels\n",
        "        self.models = [SGD(n_features, **sgd_kwargs) for _ in range(n_labels)]\n",
        "\n",
        "    def fit(self, X: np.ndarray, Y: np.ndarray):\n",
        "        for idx in range(self.n_labels):\n",
        "            self.models[idx].fit(X, Y[:, idx])\n",
        "\n",
        "    def decision_function(self, X: np.ndarray) -> np.ndarray:\n",
        "        return np.column_stack([m.decision_function(X) for m in self.models])\n",
        "\n",
        "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
        "        return (self.decision_function(X) >= 0).astype(np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "sdg= OneVsRestSGD(\n",
        "    n_labels= len(LABEL_COLUMNS),\n",
        "    n_features= X_train_tfidf.shape[1],\n",
        "    C=1.0,\n",
        "    lr=0.01,\n",
        "    epochs=5\n",
        ")\n",
        "sdg.fit(X_train, y_train.values.astype(np.int8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SDG-RULE BASED HYBRID PERFORMANCE \n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Age       0.85      0.94      0.90       304\n",
            "      Gender       0.74      0.89      0.81       281\n",
            "    Physical       0.59      0.64      0.61       293\n",
            "        Race       0.88      0.78      0.83       201\n",
            "    Religion       0.92      0.87      0.89       290\n",
            "    Politics       0.91      0.86      0.89       227\n",
            "      Others       0.35      0.81      0.49       310\n",
            "\n",
            "   micro avg       0.66      0.83      0.74      1906\n",
            "   macro avg       0.75      0.83      0.77      1906\n",
            "weighted avg       0.73      0.83      0.76      1906\n",
            " samples avg       0.71      0.84      0.75      1906\n",
            "\n",
            "Hamming Loss: 0.0927996054578333\n",
            "Subset Accuracy: 0.5368239355581128\n"
          ]
        }
      ],
      "source": [
        "y_combined_pred = hybrid_predict(X_combined_original.tolist(), vectorizer, sdg, RULE_LEXICONS, LABEL_COLUMNS)\n",
        "\n",
        "print(\" SDG-RULE BASED HYBRID PERFORMANCE \")\n",
        "evaluate(y_combined.values, y_combined_pred, LABEL_COLUMNS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Age       0.69      0.96      0.80       304\n",
            "      Gender       0.65      0.97      0.78       281\n",
            "    Physical       0.41      0.85      0.55       293\n",
            "        Race       0.43      0.94      0.59       201\n",
            "    Religion       0.88      0.92      0.90       290\n",
            "    Politics       0.65      0.89      0.75       227\n",
            "      Others       0.44      0.88      0.58       310\n",
            "\n",
            "   micro avg       0.56      0.92      0.69      1906\n",
            "   macro avg       0.59      0.92      0.71      1906\n",
            "weighted avg       0.60      0.92      0.71      1906\n",
            " samples avg       0.65      0.92      0.73      1906\n",
            "\n",
            "Hamming Loss: 0.12715765247410818\n",
            "Subset Accuracy: 0.3947065592635213\n"
          ]
        }
      ],
      "source": [
        "# pure model-only prediction\n",
        "y_pred = sdg.predict(X_combined)\n",
        "evaluate(y_combined.values, y_pred, LABEL_COLUMNS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2605/2605 [00:01<00:00, 1702.70 examples/s]\n",
            "Map: 100%|██████████| 435/435 [00:00<00:00, 1663.64 examples/s]\n",
            "Map: 100%|██████████| 1303/1303 [00:00<00:00, 1924.23 examples/s]\n"
          ]
        }
      ],
      "source": [
        "#MBERT Performance\n",
        "# Load pre-trained mBERT model and tokenizer\n",
        "# 60/30/10\n",
        "X_temp, X_val_original, y_temp, y_val = train_test_split(\n",
        "    df[\"clean_text\"], df[LABEL_COLUMNS], test_size=0.10, random_state=42\n",
        ")\n",
        "\n",
        "X_train_original, X_test_original, y_train, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3333, random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"clean_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_hf = HFDataset.from_pandas(X_train_original.to_frame(name='clean_text'))\n",
        "val_hf = HFDataset.from_pandas(X_val_original.to_frame(name='clean_text'))\n",
        "test_hf = HFDataset.from_pandas(X_test_original.to_frame(name='clean_text'))\n",
        "\n",
        "\n",
        "train_enc = train_hf.map(tokenize)\n",
        "val_enc = val_hf.map(tokenize)\n",
        "test_enc = test_hf.map(tokenize)\n",
        "\n",
        "def add_labels(encodings, labels):\n",
        "    encodings_with_labels = []\n",
        "    for i, encoding in enumerate(encodings):\n",
        "        encoding_copy = dict(encoding)\n",
        "        encoding_copy['labels'] = labels[i].tolist()\n",
        "        encodings_with_labels.append(encoding_copy)\n",
        "    return encodings_with_labels\n",
        "\n",
        "train_enc_with_labels = add_labels(list(train_enc), y_train.values)\n",
        "val_enc_with_labels = add_labels(list(val_enc), y_val.values)\n",
        "test_enc_with_labels = add_labels(list(test_enc), y_test.values)\n",
        "\n",
        "for name, dset in zip(\n",
        "    [\"train_enc\", \"val_enc\", \"test_enc\"],\n",
        "    [train_enc, val_enc, test_enc]\n",
        "):\n",
        "    cols_to_remove = []\n",
        "    if \"clean_text\" in dset.column_names:\n",
        "        cols_to_remove.append(\"clean_text\")\n",
        "    if \"__index_level_0__\" in dset.column_names:\n",
        "        cols_to_remove.append(\"__index_level_0__\")\n",
        "    if cols_to_remove:\n",
        "        dset = dset.remove_columns(cols_to_remove)\n",
        "    locals()[name] = dset  # update the variable in the local scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch dataset\n",
        "class HateSpeechTorchDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(self.encodings[idx][\"input_ids\"], dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(self.encodings[idx][\"attention_mask\"], dtype=torch.long),\n",
        "            \"labels\": torch.tensor(self.encodings[idx][\"labels\"], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "train_dataset = HateSpeechTorchDataset(train_enc_with_labels)\n",
        "val_dataset = HateSpeechTorchDataset(val_enc_with_labels)\n",
        "test_dataset = HateSpeechTorchDataset(test_enc_with_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mBERTHateSpeechClassifier(nn.Module):\n",
        "    def __init__(self, n_labels, dropout=0.1):\n",
        "        super(mBERTHateSpeechClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, n_labels)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, device, epochs=3, lr=2e-5):\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "    # Learning rate scheduler\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
        "        for batch in train_pbar:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            logits = model(input_ids, attention_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            \n",
        "            total_train_loss += loss.item()\n",
        "            train_pbar.set_postfix({'loss': loss.item()})\n",
        "        \n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        \n",
        "        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]')\n",
        "        with torch.no_grad():\n",
        "            for batch in val_pbar:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                \n",
        "                logits = model(input_ids, attention_mask)\n",
        "                loss = criterion(logits, labels)\n",
        "                \n",
        "                total_val_loss += loss.item()\n",
        "                val_pbar.set_postfix({'loss': loss.item()})\n",
        "        \n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{epochs}:')\n",
        "        print(f'  Average training loss: {avg_train_loss:.4f}')\n",
        "        print(f'  Average validation loss: {avg_val_loss:.4f}')\n",
        "        \n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_mbert_model.pth')\n",
        "            print(f'  New best model saved!')\n",
        "        \n",
        "        print()\n",
        "    \n",
        "    return train_losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader, device, threshold=0.5):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_probabilities = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Evaluating'):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            logits = model(input_ids, attention_mask)\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities > threshold).float()\n",
        "            \n",
        "            all_predictions.append(predictions.cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            all_probabilities.append(probabilities.cpu().numpy())\n",
        "    \n",
        "    predictions = np.vstack(all_predictions)\n",
        "    labels = np.vstack(all_labels)\n",
        "    probabilities = np.vstack(all_probabilities)\n",
        "    \n",
        "    return predictions, labels, probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Model loaded with 7 labels\n",
            "Total parameters: 167,361,799\n",
            "Starting training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3 [Train]:   2%|▏         | 3/163 [04:47<4:15:21, 95.76s/it, loss=0.662] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[90], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Run the training\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 60\u001b[0m     model, predictions, probabilities, train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[90], line 24\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\n\u001b[0;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_mbert_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "Cell \u001b[1;32mIn[88], line 30\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, device, epochs, lr)\u001b[0m\n\u001b[0;32m     26\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 30\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[87], line 9\u001b[0m, in \u001b[0;36mmBERTHateSpeechClassifier.forward\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[0;32m     11\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1144\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1144\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1157\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Using device: {device}')\n",
        "    \n",
        "    # Get number of labels from your data\n",
        "    n_labels = y_train.shape[1]  # Assuming y_train is your multilabel target\n",
        "    \n",
        "    # Create data loaders\n",
        "    batch_size = 16\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = mBERTHateSpeechClassifier(n_labels=n_labels)\n",
        "    model.to(device)\n",
        "    \n",
        "    print(f'Model loaded with {n_labels} labels')\n",
        "    print(f'Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
        "    \n",
        "    # Train model\n",
        "    print('Starting training...')\n",
        "    train_losses, val_losses = train_model(\n",
        "        model, train_loader, val_loader, device, \n",
        "        epochs=3, lr=2e-5\n",
        "    )\n",
        "    \n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('best_mbert_model.pth'))\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    print('Evaluating on test set...')\n",
        "    predictions, labels, probabilities = evaluate_model(model, test_loader, device)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    exact_match = accuracy_score(labels, predictions)\n",
        "    hamming = hamming_loss(labels, predictions)\n",
        "    \n",
        "    print(f'Test Results:')\n",
        "    print(f'Exact Match Ratio: {exact_match:.4f}')\n",
        "    print(f'Hamming Loss: {hamming:.4f}')\n",
        "    \n",
        "    # Per-label classification report\n",
        "    label_names = [f'Label_{i}' for i in range(n_labcudaels)]  # Replace with actual label names if available\n",
        "    \n",
        "    for i in range(n_labels):\n",
        "        print(f'\\nLabel {i} ({label_names[i]}):')\n",
        "        report = classification_report(\n",
        "            labels[:, i], predictions[:, i], \n",
        "            target_names=['Not Present', 'Present'],\n",
        "            digits=4\n",
        "        )\n",
        "        print(report)\n",
        "    \n",
        "    return model, predictions, probabilities, train_losses, val_losses\n",
        "\n",
        "# Run the training\n",
        "if __name__ == \"__main__\":\n",
        "    model, predictions, probabilities, train_losses, val_losses = main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
